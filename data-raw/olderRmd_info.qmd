
### An Example

The data requirements for the __aspm__ are described above and for the next example we will use the _dataspm_ built in data set. First we will examine an example using only two parameters (assuming the population begins in an unfished state) and then extend the model fitting to include the possibility of an initially depleted state. The two parameters being fitted are the average unfished recruitment level and the standard deviation of the errors around the CPUE data. 

We load _dataspm_, which contains a dataframe of the catches and CPUE by year (*fish*) and other parameters used for the age-structured production model. 

```{r "aspmData", echo=TRUE}
library(datalowSA)
data(dataspm)
fish <- dataspm$fish
props <- dataspm$props # length-, weight-, maturity- and selectivity-at-age

```

While a simple, aggregated biomass surplus production model only requires the specification of the species name in the _glb_ data object an __aspm__ requires information on the growth, selectivity, weight-at-age, steepness of the stock-recruit relationship and natural mortality. The global parameters (_glb_), in addition to the _spsname_, need to contain the population ages (*maxage* and _ages_), natural mortality (*M*), von Bertalanffy growth parameters (*Linf*, _K_ and _t0_), weight-at-age parameters (*Waa* and _Wab_), age at 50% maturity, delta (*M50a* and _deltaM_), age that 50% of the population are selected by the gear and delta (*sela50* and _deltaS_) and the _steepness_ of the stock-recruitment relationship. The number of years (*nyrs*) of over which catch and CPUE are available (including missing years) is calculated from the *fish* dataframe. A starting value for the log of the initial recruitment (*R0*) also needs to be provided, although this will be estimated along with the standard deviation of the errors around the CPUE data. 

We inspect the global parameters specified in _dataspm_.

```{r}
(glb <- dataspm$glb)

```

Just as with the __spm__ model Fitting an __aspm__ model entails first finding initial parameter estimates that lead to predicted cpue time-series that approximate the observed series. Thus, one might begin something like this and uses aspmLL to determine the negative log-likelihood (-verLL), then _dynamics_ to calculate the dynamics of the __aspm__, and finally _plotASPM_ to illustrate the quality of fit to help decide whether changes are required to the initial guesses.:

```{r "guessparam", fig.width=7,fig.height=4.5}
pars <- c(12.9,0.25)
aspmLL(pars,infish=fish,inglb=glb,inprops=props)
fishery <- dynamics(pars,infish=fish,inglb=glb,inprops = props)
plotASPM(fishery)

```

__Figure 1.__ The outcome of a first guess at a two parameter version of the __aspm__. clearly the fit is very poor and the strong trends in the predicted cpue, the log-normal residuals, and the annual harvest rate bumping up against the built-in upper limit of 0.85 across numerous years, provide a strong indication that the initial guess at unfished average recruitment parameter (_R0_) is too small. Try increasing it slowly to see its effect on the model fit to the data.

Once reasonable starting values have been found for the parameters ($R_0$ the unfished average recruitment and $\hat\sigma_{I}$, the standard deviation associated with fitting the observed cpue) then an attempt at fitting the model to the data formally can be made using code something like this:


```{r "firstASPM", echo=TRUE, warning=FALSE}

# pars <- c(13.7,0.19)
# ans <- fitASPM(pars,infish=fish,inglb=glb,inprops=props)
# outfit(ans) # a tidier way of printing the list output from optim
# fishery <- dynamics(ans$par,infish=fish,inglb=glb,inprops = props)

```


__Table 1.__ The output from the _fitASPM_ function and the _dynamics_ function.
```{r printfishery, echo=TRUE}
kable(fishery,digits=c(0,3,3,3,3,3,4,4,3))
```

Note the predicted catches are identical to the observed catches. The catches are assumed to be known accurately and so as to ensure a close match between the predicted and observed catches _aspmLL_ has a simple sum-of-squared deviations penalty built into it (try _aspmLL_, without brackets in the console). This is usually sufficient to force the solution to generate a close match once plausible parameter values are found. Note that with respect to reproduction only the average unfished recruitment is estimated. In its current form the __aspm__ cannot take into accoutn strong and weak cohorts; this remains a very simple model of the dynamics. 

To visualize the output of the model fitting we can plot some of the variables from the fishery information generated by the _dynamics_ function.

```{r plot2pars, echo=TRUE, fig.width=7, fig.height=4.5, fig.align="center"}
plotASPM(fishery,CI=NA)
```

__Figure 2.__ The outcome of fitting a two parameter age-structured production model to the available data. Included is a plot of the catch history, the predicted spawning biomass, the CPUE, the harvest rate, the log-normal residuals for the cpue, and the predicted depletion.

The two-parameter model manages to capture the main cpue trends but fails to capture some of the more obvious and more rapid consistent changes in cpue (__Figure 2__). The example fishery in question was known to have been fished prior to 1985 so in the year the data begin to be available the stock can be expected to be depleted to some extent. Thus, an alternative might be to fit the model using three parameters. The first approach, with only one parameter of real interest, required data from the beginning of the fishery. However, there are many fisheries for which data are only available after the fishery has been running for a number of years. In such cases it is necessary to estimate the level of depletion and its effect upon recruitment and thus requires two parameters of interest to the dynamics. The first is, as before, the unfished recruitment level, $R_0$, but then we use a parameter that defines the initial depletion at the start of the observations ($D_{init}$. If this parameter is present in _pars_ a search is made for the constant harvest rate that when applied to the initial unfished stock leads to the predicted initial depletion level, only then does the model fitting proceed. Any initial depletion will influence the recruitment depending on the assumed steepness of the stock recruitment relationship, which is assumed to be a Beverton-Holt relationship. The _dataspm_ data set is not particularly suited to a two-parameter model even though that arrangement was able to provide a result; these assessments should not be done automatically, it always takes some background knowledge to ensure that any methods or choices applied are valid.

As an alternative two-parameter example, the deep water fishery data _data(fishdat)_ was a fishery with catch data from the very start of the fishery, which means it is better suited to using a simple two parameter model

```{r "ASPM_deep", echo=TRUE}
# data(fishdat)
# fish <- fishdat$fish
# glb <- fishdat$glb
# props <- fishdat$props
# pars <- c(14,0.3)
# ans <- fitASPM(pars,infish=fish,inglb=glb,inprops = props)
# str(ans)
```

The output contains the estimates of the optimum parameters, the final log-likelihood estimate, the number of iterations it needed to find the optimum, and some diagnostic information. The statement _convergence: int 0_ implies the solution appears valid, and no warning messages is also encouraging; but see later concerning how to test the robustness of such model fitting. If we put the fitted optimum parameters into the function _dynamics_ we can see the time-series of the more important population variables implied by the model fit.

```{r thedynamics, echo=TRUE}
fishery <- dynamics(bestL3$par,infish=fish,inglb=glb,inprops = props)
print(fishery)

```

The use of _fitASPM_ is basically shorthand for using _bestL <- optim(pars, aspmLL, method="Nelder-Mead", infish=fish, inglb=glb, inprops=props, control=list(maxit = 1000, parscale = c(10,1)))_ twice in a row. Examine its code by using _fitASPM_ without brackets in the R console window.

Note that the harvest rate in 1996 appears to have bumped up against the upper limit of 0.85 hard wired into the R-code (try typing _dynamics_ into the R console without brackets to see the code). So that 1180 tonnes catch in 1996 was likely to be damaging. However, the predicted catch is only slightly less than the reported catch so this spike in harvest rate has some support in the data. Plotting up the fishery results enables the visualization of the impact of the fishery and he effect of cutting back catches.

```{r addCI, echo=TRUE, fig.width=7,fig.height=5.5, fig.align="center"}
ceCI <- getLNCI(fishery[,"PredCE"],bestL3$par[2])
plotASPM(fishery,CI=ceCI)

```

__Figure 3.__ The outcome of fitting a two parameter age-structured production model to the deep-water fishery data. Only the CPUE with confidence intervals are plotted.

The modelling suggests that once catches were reduced to an average of about 246 t between 1997 - 2005 the stock began to very slowly recover, then, after catches were further reduced from 2007 onwards (due to a deepwater closure and cessation of targeting) the rate of recover was predicted to have increased. The model predicts that the stock breached above the 0.2$B_{0}$ limit reference point in about 2010. However, extrapolation beyond the data must always be treated with a great deal of caution. The uncertainty about the catch rates is relatively large, especially because of the records from 1992, 2005, and 2006 deviate so much from the rest of the trend. Without confirmation from other data the predicted recovery from 2007 onwards is purely dirven by the predictions from the fitted model. The predicted recovery should not be accepted on the basis of the model fit alone, there needs to be other data confirming such a recovery.
Whether the predicted recruitment from the model actually happened would require auxilliary information or data to corroborate the prediction. With Orange Roughy, because the fishery was so short lived and they only mature between 31 - 35 years of age, the biology suggested that the fishery is still receiving unfished recruitment levels, which can be expected to decline once the recruits produced from the depleted population are supposed to begin entering the fishery. 
However, given the lowest point of the stock is predicted to have occurred in 1996 the expected minimum in recruitment should only occur in about 2026 - 2030.  

One way of estimating confidence intervals around the cpue is to use the standard deviation estimates from the likelihood fitting of the CPUE (parameter 2) and set up log-normal error bars, but later we will consider bootstrap percentile confidence intervals as an alternative.

It is not surprising the bounds on the predicted CPUE become vary wide in the regions where there are no cpue data. But even where there are data the bounds are wide. A better estimation of the uncertainty is more likely to be generated by the bootstrap analysis. The variation expressed is primarily driven by the elevated values in 1992 and in 2005 and 2006. The period from 1989 - 2006 is assumed to related to when aggregations were not being targeted but occasionally, no doubt, smaller aggregations would have added heterogeneity to the cpue data. Certainly given this uncertainty it remains questionable whether one could validly claim that the likelihood of the limit reference point being passed was high based only on these data. It would be best to test the robustness of this result to the initial conditions by trialing the model fit using a large array of initial parameter values just to see whether the optimum result was repeatable and stable. We will consider this after introduicing the three parameter models.

## A three parameter model

Returning to the _dataspm_ data set it is possible to use a three parameter model to fit this data accepting that the observations began when the stock had already been fished and would be expected to be partially depleted. There are details that need attention if we are to assume such a model structure. These are mathematical models and they can exhibit mathematical behaviour, such as negative recruitment or initial depletions much greater than 1.0, unless such behaviour is controlled. To avoid initial depletions > 1.0 we have implemented a slightly different maximum likelihood function so we should use _aspmPENLL_ instead of _aspmLL_. In this case, where the initial depletion is estimated to be a long way below 1.0 it might not matter, but such penalties can stabilize even such supposedly safe parameter sets.

```{r threepars, echo=TRUE,fig.width=7,fig.height=5,fig.align="center"}
data(dataspm)
fish <- dataspm$fish
glb <- dataspm$glb
props <- dataspm$props
pars <- c(14,0.19,0.6) # Fit 3 par__aspm__with penalty
# pars <- c(13.2794439,0.1731744,0.4933178) # for a second time through
scalepar <- magnitude(pars)
bestL <- optim(pars,aspmPENLL,method="Nelder-Mead",
              infish=fish,inglb=glb,inprops=props,
              control=list(maxit = 1000,parscale=scalepar))
outfit(bestL)
fisheryPen <- dynamics(bestL$par,infish=fish,inglb=glb,inprops=props)
ceCI <- getLNCI(fisheryPen[,"PredCE"],bestL$par[2])
plotASPM(fisheryPen,CI=ceCI)
```

__Figure 4.__ The outcome of fitting a three-parameter age-structured production model to the slope fishery data. 


Once again the model fails to capture the more rapid changes in the predicted dynamics but does capture the general trends through time (__Figure 4__). Unlike the two-parameter model it predicts a final depletion close to 50% rather than 60% but this time suggests the starting depletion was about 65% rather than 100%. However, the -ve log-likelihood in this case is -9.95 rather than -7.58 as with the two-parameter model, indicating a slightly better fit (an improvement > 1.96 for each additional parameter suggests a better fit; Venzon and Moolgavkar, 1988).

Despite the improved fit to the data the confidence intervals around the CPUE remain very large. Thus, using the three parameter model one should test the robustness of this fit to the initial conditions to determine whether or not the outcome is stable following the model fitting or whether there is variation (uncertainty) and if so how much. 

### Testing the Robustness of the Model Fit

The sensitivity of the model fit to the initial parameter values is important to explore to gain greater confidence that the solution one finds is a global optimum rather than some local minima on the log-likelihood surface.

To test for robustness of the model fit we can use the original optimal model parameters or the original guesses, add variation to them, and re-fit the model. This process should enable an analysis of the stability of the modelling outcomes. If the optimum parameters are used then add more variation to enusre the parameter space is covered. The first parameter is $Log \left( R_0 \right)$ so to simplify the selection of random variations away from the original it helps to return that parameter to the linear scale and only when finished return it to the log-scale.

```{r robustness, echo=TRUE }
  set.seed(12335)  # to get repeatable results, normally you would not do this
  data(fishdat)
  fish <- fishdat$fish
  glb <- fishdat$glb
  props <- fishdat$props
  pars <- c(14,0.3)
  out <- robustASPM(pars,fish,glb,props,scaler=20,N=15,console=FALSE)
  str(out)
  print(round(out$results,4))

```

Starting with the deep water fishery data _fishdat_ we find that 11 out of 15 generate one solution, which appears to be optimum, while the remaining four, which all began with highly unlikely first guesses (_iLike_, the initial likelihood was large) all gave implausible outcomes. It would be sensible to explore this lack of robustness further by using many more iterations. However, given the variation in the cpue data this is not a surprising result. 

If we test the robustness of the model fit to the _dataspm_ data set (a three parameter model) similar outcomes arise.


```{r robustdataspm, echo=TRUE }
  set.seed(12235)  # to get repeatable results, normally you would not do this
  data(dataspm)
  fish <- dataspm$fish
  glb <- dataspm$glb
  props <- dataspm$props
  pars <- c(14,0.2,0.6)
  out <- robustASPM(pars,fish,glb,props,scaler=15,N=10,console=FALSE)
  print(round(out$results,3))
  print(round(out$range,3))
```

Here we find that four final negative log-likelihoods differ from the optimum, although in this case the differences are not too far from the optimum. Very slight differences in the parameters even with the optimum -veLL lead to small differences in the derived statistics such as MSY and $B_0$. Once again the variation in the cpue data is what leads to this instability. Whatever the case it is to be hoped that these examples illustrate that one should never accept the final result of fitting a model even if the diagnostics look acceptable (the plot, the -veLL value, and optim gives convergence = 0). Without testing the robustness it is possible that one is settling for only a local minima. This is one reason why it is usually a good idea to run a fitting routine twice, once from the initial parameter guesses, the second time from the solution of the first time.

When testing the robustness ideally one would run very many trials (at least 100 to allow for proportional attribution of variation), in which case it becomes a reasonable proposition to plot the results. The correlations between the parameters can also be calculated (they tend ot be very high).

```{r correlations, echo=TRUE, fig.width=7,fig.height=6, fig.align="center"}
cor(out$results[,c("LnR0","Depl","-veLL","MSY")])  # correlations between outputs
 #plotprep(width=8,height=6)
intensity <- 2   #  how many points overlapping = maximum colour
pairs(out$results[,c("LnR0","Depl","-veLL","MSY")],pch=16,
      col=rgb(1,0,0,1/intensity),font=7,font.labels = 7)

```

__Figure 5.__ The correlations between outputs from repeated trials starting from different initial parameter values. Usually one would use many more trials than the example of 10, then these plots might be more informative. Histograms of these values might also indicate the variation present. 

### The Production Curve and Statistics

Using two runs through the _optim_ function each time the median of the different trials is very similar to the optimum model fit so we will use those values to determine the production curve predicted by the model We can then use that to estimate the biomass at the target (default = 0.48$B_{0}$) and at the limit reference point of 0.2$B_{0}$. In addition, by estimating the yield expected at those reference points and dividing that through by the biomass at those reference points we can calculate the target and limit harvest rate reference points. The contents of _prod_ can be used to determine other statistics such as the sustainable yield over the range of the current predicted depletion levels.

```{r production_curve, echo=TRUE,fig.width=7,fig.height=5,fig.align="center"}
data(dataspm)
fish <- dataspm$fish
glb <- dataspm$glb
props <- dataspm$props
pars <- c(13.75,0.189667,0.6) # Fit 3 par__aspm__with penalty
bestL <- optim(pars,aspmPENLL,method="Nelder-Mead",
              infish=fish,inglb=glb,inprops=props,
              control=list(maxit = 1000, parscale = c(10,1,0.1)))
# two times through
bestL <- optim(bestL$par,aspmPENLL,method="Nelder-Mead",
              infish=fish,inglb=glb,inprops=props,
              control=list(maxit = 1000, parscale = c(10,1,0.1)))
par <- bestL$par
print(par)
prod <- getProduction(exp(par[1]),fish,glb,props,
                      Hrg=c(0.01,0.45,0.005),nyr=50)
head(round(prod,3),6)
tail(round(prod,3),6)
anspen <- prodASPM(prod,target=0.48,console=FALSE,plot=TRUE)
round(anspen,3)

```

__Figure 6.__ Production curves for the optimum fitting three parameter age-structured production model fitted to the slope fishery data in _dataspm_. The target in this case is 0.48$B_{0}$ designated by the vertical green lines. The results contained within _anspen_ are used as labels. In this case it is suggesting that $B_{MSY}$ is down at 0.243$B_{0}$ so in this case using a target of 0.48$B_{0}$ means that the harvest rate, and presumably effort, would be halved, the stock kept at a much higher presumably more resilient level, and the catch only reduced on average by about 18%.


### A Phase Plot

The final part of age-structured production modelling would entail generating a phase plot of predicted biomass against the predicted harvest rates. The previous functions and analyses will provide all the information we require to feed into the function _aspmphaseplot_.

```{r phaseplot, echo=TRUE, fig.width=7,fig.height=6,fig.align="center"}
#   plotprep(width=7,height=5.5)
fisheryPen <- dynamics(bestL$par,infish=fish,inglb=glb,inprops=props)
outs <- aspmphaseplot(fisheryPen,prod,anspen,Blim=0.2,fnt=7)

```

__Figure 7.__ Phase plot of predicted biomass vs predicted harvest rate for the optimum fitting three parameter age-structured production model fitted to the slope fishery data in _dataspm_. The target in this case at 0.48$B_{0}$ is designated by the green lines, while the limit reference points are designated by the red lines. 

The phase plot (__Figure 7__) suggests that the biomass is a little below the target but the fishing mortality is very close to its target. In addition the fishery appears relatively stable at present indicating it is not declining. In the SAFS system this fishery could defensibly be claimed to be sustainable although the uncertainty in the analysis would need to be noted explicitly.

### Characterization of Uncertainty

When only fitting to CPUE it is possible to use many replicate bootstrap samples followed by reanalysis to generate a detailed characterization of uncertainty. The following example code illustrates the approach. First we need to obtain the optimum solution.


```{r bootstrapsetup, echo=TRUE, fig.width=7,fig.height=5}
#  library(datalowSA)
# library(fmr)
# data(dataspm)
# fish <- dataspm$fish
# glb <- dataspm$glb
# props <- dataspm$props
# pars <- c(13.5,0.18,0.5)
# bestL <- fitASPM(pars,fish,glb,props,callfun=aspmPENLL)
# fishery <- dynamics(bestL$par,fish,glb,props)
# kable(fishery,digits=c(0,1,1,3,3,3,3,3,3))

```

Having run the model through optim twice inside _fitASPM_ the optimum fit is used to characterize the dynamics using _dynamics_. The basis of the bootstrap sampling is that the log-normal residuals (_CPUE_/_PredCE_) are randomly sampled with replacement with each such bootstrap then being multiplied by the optimum model's predicted CPUE. If, for example, we take the original residuals and multiply them by the original predicted CPUE we would re-generate the original observed CPUE. All we are doing in the bootstrap procedure is reordering the residuals by randomly resampling them with replacement. The 'with replacement' bit implies that some values may be omitted and others may be repeated more than once.

Such bootstrap samples are generated within _bootASPM_. This function generates replicate numbers of optimal fitting parameters in _param_, estimates of unfished biomass in _B0_, and finally a matrix of five time-series of Spawning Biomass, Fully selected harvest rate, each bootstrap CPUE series, the optimum predicted CPUE, and the depletion level through time. Here we are only running 100 replicates so as to speed the process, but in a real analysis one might use at least 1000 replicates

```{r takebootstrap, echo=TRUE}
# reps <- 20
# starttime <- Sys.time()
# answer <- bootASPM(fish,glb,props,bestL$par,iter=reps)
# Sys.time() - starttime
# str(answer,max.level=1)

```

Once the bootstraps are completed there are multiple ways of displaying such information. Initially one can generate classical percentile confidence intervals from the bootstrap replicates (Haddon, 2011).

```{r finalyear, echo=TRUE, fig.width=7,fig.height=6}
# yrs <- fishery[,"Year"]
# nyrs <- length(yrs)
# par(mfrow=c(2,2),mai=c(0.45,0.45,0.05,0.05)) 
# par(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)  
# label <- names(answer$result[1,1,])
# label <- label[-3]  # remove CPUE
# numvar <- length(label)
# bootvar <- answer$result[,nyrs,label[1]]
# for (i in 1:numvar) { # i=3
#    bootvar <- answer$result[,nyrs,label[i]]
#    quantCI <- quantile(bootvar,probs=c(0.05,0.5,0.95),na.rm=TRUE)
#    hist(bootvar,breaks=30,main="",xlab=label[i],col="red")
#    abline(v=quantCI,col=c(4,4,4),lwd=c(1,2,1))
# }
```

__Figure 7.__ Histograms of the final years' spawning biomass, fully selected harvest rates, predicted CPUE, and the stock depletion level. Of course 20 replicates is completely inadequate but each bootstrap replicate can take a significant time (note the time taken in the example). One thing that can be noted is the asymmetrical percentile confidence bounds.


With only 20 replicates no conclusions can be drawn but the plots still illustrate the principle behind the bootstraps. The percentile confidence intervals can illustrate the uncertainty in the assessments and the potential risk of falling below limit reference points.


```{r perceCI, echo=TRUE}
# pickvar <- "Deplete"
# bootvar <- answer$result[,,pickvar]
# yrs <- as.numeric(colnames(bootvar))
# nyrs <- length(yrs)
# quantCI <- t(apply(bootvar,2,quants))
# kable(quantCI,digits=c(3,3,3,3,3,3))
```


```{r plottimeseries, echo=TRUE, fig.width=7,fig.height=4.5}
# ymax <- getmaxy(bootvar)
# par(mfrow=c(1,1),mai=c(0.45,0.45,0.05,0.05)) 
# par(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)
# plot(yrs,bootvar[1,],type="n",lwd=1,col=0,ylim=c(0,ymax),
#      panel.first = grid(),xlab="",ylab=pickvar)
# for (i in 1:reps) lines(yrs,bootvar[i,],lwd=1,col="grey")
# lines(yrs,quantCI[,"50%"],lwd=2,col="red")
# arrows(x0=yrs,y0=quantCI[,"5%"],y1=quantCI[,"95%"],
#        col=2,lwd=1,length=0.035,angle=90,code=3)
```

__Figure 8.__ The bootstrapped trajectories of stock depletion of the dataspm data set. Note that 20 replicates are far too few to provide sensible or valid percentile confidence intervals.


The output from the _bootASPM_ function includes the bootstrap optimum parameters. These can be used along with the _fish_, _glb_, and _props_ objects from the data set used to generate productivity curves and determine target catches, MSY, and other fishery outputs for each set of parameters. This means that percentile confidence intervals can be generated for such assessment outputs. 

